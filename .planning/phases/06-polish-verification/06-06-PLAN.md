---
phase: 06-polish-verification
plan: 06
type: execute
wave: 2
depends_on: ["06-02"]
files_modified:
  - config/config_test.go
  - config/constants_test.go
  - internal/usecase/repo/project_repo_test.go
  - internal/usecase/repo/modul_repo_test.go
  - internal/usecase/repo/user_repo_test.go
autonomous: true

must_haves:
  truths:
    - "Test coverage for config package increases from 32.5% to at least 60%"
    - "Test coverage for usecase/repo package increases from 65.5% to at least 80%"
    - "All new tests pass without failures"
    - "No existing tests are broken by new test additions"
  artifacts:
    - path: "config/config_test.go"
      provides: "Tests for config package critical paths"
    - path: "internal/usecase/repo/project_repo_test.go"
      provides: "Additional tests for project repository"
    - path: "internal/usecase/repo/modul_repo_test.go"
      provides: "Additional tests for modul repository"
  key_links:
    - from: "config/config_test.go"
      to: "config/config.go"
      via: "LoadConfig and env var parsing"
      pattern: "LoadConfig|getEnvAs"
    - from: "internal/usecase/repo/*_repo_test.go"
      to: "internal/usecase/repo/*_repo.go"
      via: "repository method coverage"
      pattern: "func.*Test.*Repo"
---

<objective>
Audit test coverage across the codebase and add missing tests for the two priority packages: config (32.5% coverage) and usecase/repo (65.5% coverage). This addresses the locked user decision to "audit untested critical paths and add missing tests."

Purpose: Close the test coverage gaps identified during research, ensuring critical startup code (config) and data access layer (usecase/repo) are adequately tested.
Output: Improved test coverage for config and usecase/repo packages, coverage report documenting before/after metrics.
</objective>

<execution_context>
@/home/ilmannafi/.claude/get-shit-done/workflows/execute-plan.md
@/home/ilmannafi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-polish-verification/06-RESEARCH.md
@.planning/phases/06-polish-verification/06-02-SUMMARY.md
@config/config.go
@config/config_test.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run coverage audit and add tests for config package</name>
  <files>
    config/config_test.go
    config/constants_test.go
  </files>
  <action>
  First, run a full coverage audit to establish current baselines, then add tests for the config package.

  **Step 1: Coverage baseline**
  Run `go test -cover ./... 2>&1 | grep -E "ok|FAIL" | sort` to capture current coverage for all packages. Save this output as the "before" baseline.

  Pay special attention to:
  - `config` package: expected ~32.5%
  - `internal/usecase/repo` package: expected ~65.5%

  **Step 2: Identify untested paths in config package**
  Run `go test -coverprofile=config_cover.out ./config/ && go tool cover -func=config_cover.out` to see exactly which functions are untested.

  Expected gaps (from research):
  - `LoadConfig` edge cases (missing env vars, invalid values, defaults)
  - `getEnvAsInt`, `getEnvAsBool`, `getEnvAsFloat64` helper functions
  - Database connection setup paths
  - Config validation logic

  **Step 3: Add config package tests**
  Add tests to `config/config_test.go` (or create if it doesn't exist) covering:

  1. **LoadConfig with defaults:** Call LoadConfig without setting any env vars and verify all default values are correctly applied. Use `t.Setenv()` to control environment.

  2. **LoadConfig with custom values:** Set all env vars via `t.Setenv()` and verify they are read correctly.

  3. **getEnvAsInt edge cases:** Test with valid int, invalid string, empty string, negative numbers.

  4. **getEnvAsBool edge cases:** Test with "true", "false", "1", "0", invalid string, empty string.

  5. **getEnvAsFloat64 edge cases:** Test with valid float, invalid string, empty string.

  6. **Config validation:** Test that missing critical env vars (like SUPABASE_URL if required) produce appropriate errors or defaults.

  Follow existing test patterns in the codebase:
  - Use `testify/assert` and `testify/require`
  - Use `t.Setenv()` for environment variable manipulation (automatically restores after test)
  - Use table-driven tests where appropriate
  - Keep each test function focused on one concern

  If `config/constants.go` was created in Plan 01, add a simple test in `config/constants_test.go` verifying the constant values are non-empty strings.

  IMPORTANT: If the config package functions are unexported (lowercase), test them from within the `config` package (use `package config` not `package config_test`). If they are exported, either approach works.
  </action>
  <verify>Run `go test -cover ./config/ 2>&1` -- must show PASS with coverage significantly above 32.5% (target: 60%+). Run `go test -coverprofile=config_cover.out ./config/ && go tool cover -func=config_cover.out | tail -1` to see total coverage percentage.</verify>
  <done>Config package test coverage increased from ~32.5% to at least 60%. All new tests pass. Tests cover LoadConfig defaults, custom values, env var helper edge cases, and validation paths.</done>
</task>

<task type="auto">
  <name>Task 2: Add tests for usecase/repo package critical paths</name>
  <files>
    internal/usecase/repo/project_repo_test.go
    internal/usecase/repo/modul_repo_test.go
    internal/usecase/repo/user_repo_test.go
  </files>
  <action>
  Add tests for untested critical paths in the usecase/repo package.

  **Step 1: Identify untested paths**
  Run `go test -coverprofile=repo_cover.out ./internal/usecase/repo/ && go tool cover -func=repo_cover.out` to see exactly which repository functions are untested.

  **Step 2: Analyze existing test patterns**
  Read existing test files in `internal/usecase/repo/` to understand:
  - How the test database is set up (SQLite in-memory? testcontainers? mocks?)
  - What test helpers exist (setupTestDB, etc.)
  - Whether tests use real GORM queries or mock the database

  **Step 3: Add tests for uncovered repository methods**
  Focus on the most critical untested paths:

  1. **Error paths:** Most repo tests likely cover happy paths. Add tests for:
     - Record not found (GORM ErrRecordNotFound)
     - Database connection errors
     - Constraint violation errors (duplicate keys, foreign key violations)

  2. **Query variations:** Add tests for:
     - List/Find with different filter parameters
     - Pagination edge cases (page 0, very large page)
     - Update with partial fields
     - Delete with cascading effects

  3. **Edge cases:**
     - Empty result sets
     - Nil pointer handling for optional fields
     - Context cancellation (if context.Context was added in Phase 5)

  Follow the existing test setup pattern exactly. If tests use SQLite in-memory:
  - Use the same `setupTestDB` or equivalent helper
  - Run migrations/seed as existing tests do
  - Clean up after each test

  If tests use mocks:
  - Follow the same mock patterns
  - Add `.On()` and `.Return()` for new test cases

  Do NOT add tests that require external services (PostgreSQL, Supabase).
  Do NOT modify existing passing tests.
  Keep test file sizes under 500 lines per the Phase 5 convention.
  </action>
  <verify>Run `go test -cover ./internal/usecase/repo/ 2>&1` -- must show PASS with coverage above 65.5% (target: 80%+). Run `go test -coverprofile=repo_cover.out ./internal/usecase/repo/ && go tool cover -func=repo_cover.out | tail -1` to see total coverage percentage. Run `go test ./... -count=1 2>&1 | grep FAIL` to verify no regressions.</verify>
  <done>usecase/repo package test coverage increased from ~65.5% to at least 80%. All new tests pass. Tests cover error paths, query variations, and edge cases. No regressions in other packages.</done>
</task>

</tasks>

<verification>
1. `go test -cover ./config/` shows coverage >= 60%
2. `go test -cover ./internal/usecase/repo/` shows coverage >= 80%
3. `go test ./... -count=1 2>&1 | grep FAIL` shows zero failures
4. All new test files are under 500 lines
</verification>

<success_criteria>
- Config package coverage improved from ~32.5% to at least 60%
- usecase/repo package coverage improved from ~65.5% to at least 80%
- All new tests pass
- No regressions in existing tests
- Coverage audit baseline captured (before/after metrics)
</success_criteria>

<output>
After completion, create `.planning/phases/06-polish-verification/06-06-SUMMARY.md`
</output>
